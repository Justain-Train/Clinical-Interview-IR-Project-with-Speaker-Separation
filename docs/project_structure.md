# Project Structure

Complete project skeleton for the Intelligent Clinical Interview IR System.

---

## ğŸ“ Complete Directory Tree

```
Clinical-Interview-IR-Project-with-Speaker-Separation/
â”‚
â”œâ”€â”€ README.md                          # Main project overview
â”œâ”€â”€ LICENSE                            # MIT License
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”œâ”€â”€ .env.example                       # Environment variables template
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ docker-compose.yml                 # Multi-container setup
â”‚
â”œâ”€â”€ docs/                              # ğŸ“š Documentation
â”‚   â”œâ”€â”€ architecture.md                # System design overview
â”‚   â”œâ”€â”€ data_schemas.md                # Data structure definitions
â”‚   â”œâ”€â”€ python_modules.md              # Module skeletons
â”‚   â”œâ”€â”€ setup_guide.md                 # Installation instructions
â”‚   â”œâ”€â”€ evaluation_protocol.md         # Evaluation procedures
â”‚   â””â”€â”€ system_flow_summary.md         # Flow explanation
â”‚
â”œâ”€â”€ n8n/                               # ğŸ”„ Orchestration workflows
â”‚   â”œâ”€â”€ README.md                      # n8n usage guide
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ offline_ingestion.md       # Offline pipeline flow
â”‚       â”œâ”€â”€ live_ingestion.md          # Live pipeline flow
â”‚       â”œâ”€â”€ unified_retrieval.md       # Retrieval workflow
â”‚       â””â”€â”€ evaluation.md              # Evaluation workflow
â”‚
â”œâ”€â”€ backend/                           # ğŸ”§ Core Python backend
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ api/                           # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ dependencies.py
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”œâ”€â”€ models/                        # Domain models
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â””â”€â”€ utils/                         # Shared utilities
â”‚       â”œâ”€â”€ audio_utils.py
â”‚       â”œâ”€â”€ logging_config.py
â”‚       â””â”€â”€ db_utils.py
â”‚
â”œâ”€â”€ diarization/                       # ğŸ¤ Speaker separation
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ pyannote_runner.py             # Diarization executor
â”‚   â””â”€â”€ config.py                      # Configuration
â”‚
â”œâ”€â”€ transcription/                     # ğŸ“ Speech-to-text
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ whisper_client.py              # Whisper interface
â”‚   â”œâ”€â”€ batch_transcribe.py            # Offline transcription
â”‚   â””â”€â”€ stream_transcribe.py           # Live transcription
â”‚
â”œâ”€â”€ alignment/                         # ğŸ”— Speaker-text alignment
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ speaker_aligner.py             # Alignment logic
â”‚   â””â”€â”€ segment_builder.py             # Segment creation
â”‚
â”œâ”€â”€ indexing/                          # ğŸ’¾ Data indexing
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ index_writer.py                # Write to vector DB
â”‚   â”œâ”€â”€ embedder.py                    # Embedding generation
â”‚   â””â”€â”€ schema_validator.py            # Data validation
â”‚
â”œâ”€â”€ retrieval/                         # ğŸ” Query processing
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ retriever.py                   # Search logic
â”‚   â”œâ”€â”€ ranker.py                      # Re-ranking
â”‚   â””â”€â”€ llm_explainer.py               # LLM explanations
â”‚
â”œâ”€â”€ evaluation/                        # ğŸ“Š Metrics & evaluation
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ metrics.py                     # IR metrics
â”‚   â”œâ”€â”€ evaluator.py                   # Evaluation orchestrator
â”‚   â””â”€â”€ speaker_eval.py                # Speaker-specific metrics
â”‚
â”œâ”€â”€ frontend/                          # ğŸ–¥ï¸ Web interface (optional)
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ app.py                         # Streamlit app
â”‚   â””â”€â”€ static/
â”‚
â”œâ”€â”€ tests/                             # âœ… Test suite
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ test_diarization/
â”‚   â”œâ”€â”€ test_transcription/
â”‚   â”œâ”€â”€ test_alignment/
â”‚   â”œâ”€â”€ test_indexing/
â”‚   â”œâ”€â”€ test_retrieval/
â”‚   â”œâ”€â”€ test_evaluation/
â”‚   â”œâ”€â”€ test_api/
â”‚   â”œâ”€â”€ fixtures/
â”‚   â””â”€â”€ conftest.py
â”‚
â”œâ”€â”€ scripts/                           # ğŸ› ï¸ Utility scripts
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ init_db.py                     # Database initialization
â”‚   â”œâ”€â”€ create_collections.py          # Create vector collections
â”‚   â”œâ”€â”€ download_sample_data.py        # Get sample data
â”‚   â”œâ”€â”€ health_check.py                # System health check
â”‚   â”œâ”€â”€ load_sample_data.py            # Load test data
â”‚   â”œâ”€â”€ run_evaluation.py              # Run evaluation
â”‚   â””â”€â”€ reindex_all.py                 # Reindex all data
â”‚
â”œâ”€â”€ config/                            # âš™ï¸ Configuration files
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ diarization_config.yaml
â”‚   â”œâ”€â”€ retrieval_config.yaml
â”‚   â”œâ”€â”€ evaluation_config.yaml
â”‚   â””â”€â”€ livekit.yaml
â”‚
â””â”€â”€ data/                              # ğŸ’¿ Local data (gitignored)
    â”œâ”€â”€ README.md
    â”œâ”€â”€ audio/                         # Uploaded audio files
    â”œâ”€â”€ postgres/                      # Local pgvector DB (dev only, not needed for Supabase cloud)
    â”œâ”€â”€ n8n/                           # n8n workflow data
    â”œâ”€â”€ ollama/                        # LLM models (if using local Ollama)
    â”œâ”€â”€ evaluation/                    # Test datasets and ground truth
    â””â”€â”€ sample_audio/                  # Example files for testing
```

---

## ğŸ“¦ Module Count

| Category | Count |
|----------|-------|
| Documentation files | 6 |
| Workflow descriptions | 4 |
| Python modules | ~25 |
| Configuration files | 4 |
| Test files | ~20 |
| Utility scripts | ~7 |

**Total Files (skeleton)**: ~70

---

## ğŸ”„ Data Flow Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         INGESTION LAYER (Divergent)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   OFFLINE PATH      â”‚      LIVE PATH             â”‚
â”‚                     â”‚                            â”‚
â”‚   Audio File        â”‚   LiveKit Session          â”‚
â”‚       â†“             â”‚         â†“                  â”‚
â”‚   Pyannote          â”‚   Pre-separated Streams    â”‚
â”‚       â†“             â”‚         â†“                  â”‚
â”‚   Whisper           â”‚   Per-stream Whisper       â”‚
â”‚       â†“             â”‚         â†“                  â”‚
â”‚   Alignment         â”‚   (No alignment)           â”‚
â”‚       â†“             â”‚         â†“                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
         TranscriptSegment (unified)
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         INDEXING LAYER (Unified)                  â”‚
â”‚   Validation â†’ Embedding â†’ Vector DB + Metadata   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
                Unified Index
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         RETRIEVAL LAYER (Unified)                 â”‚
â”‚   Query â†’ Retrieve â†’ Rank â†’ Explain               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
                   Results
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         EVALUATION LAYER (Unified)                â”‚
â”‚   Metrics (Overall + Speaker-Specific)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Implementation Checklist

### Phase 1: Foundation
- [ ] Set up Python environment
- [ ] Install dependencies
- [ ] Start Docker containers (Qdrant, PostgreSQL, n8n)
- [ ] Initialize database schema

### Phase 2: Offline Pipeline
- [ ] Implement diarization module
- [ ] Implement transcription module
- [ ] Implement alignment module
- [ ] Test offline ingestion end-to-end

### Phase 3: Indexing
- [ ] Implement embedder
- [ ] Implement index writer
- [ ] Implement schema validator
- [ ] Index sample data

### Phase 4: Retrieval
- [ ] Implement semantic search
- [ ] Implement keyword search
- [ ] Implement hybrid search
- [ ] Add re-ranking
- [ ] (Optional) Add LLM explanation

### Phase 5: Evaluation
- [ ] Implement metrics (P@K, R@K, MAP, NDCG)
- [ ] Create test dataset
- [ ] Implement evaluator
- [ ] Generate evaluation report

### Phase 6: Live Pipeline (Optional)
- [ ] Set up LiveKit
- [ ] Implement streaming transcription
- [ ] Connect to unified indexing
- [ ] Test live ingestion

### Phase 7: Integration
- [ ] Create n8n workflows
- [ ] Connect all components via API
- [ ] Test full system
- [ ] Document results

---

## ğŸ“š Documentation Reading Order

1. **README.md** - Project overview
2. **docs/architecture.md** - System design
3. **docs/data_schemas.md** - Data structures
4. **docs/setup_guide.md** - Get started
5. **docs/python_modules.md** - Module details
6. **n8n/workflows/*.md** - Workflow logic
7. **docs/evaluation_protocol.md** - How to evaluate
8. **docs/system_flow_summary.md** - Why this design

---

## ğŸš€ Quick Start

```bash
# 1. Clone repository
git clone <repo-url>
cd Clinical-Interview-IR-Project-with-Speaker-Separation

# 2. Set up environment
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 3. Configure environment
cp .env.example .env
# Edit .env with your settings

# 4. Start services
docker-compose up -d

# 5. Initialize database
python scripts/init_db.py

# 6. Load sample data
python scripts/load_sample_data.py

# 7. Start backend API
cd backend
uvicorn api.main:app --reload

# 8. Run tests
pytest tests/

# 9. Run evaluation
python scripts/run_evaluation.py
```

---

## ğŸ“ Next Steps

After reviewing this skeleton:

1. **Understand the architecture** (read docs/)
2. **Set up the environment** (follow setup_guide.md)
3. **Implement incrementally** (start with one module)
4. **Test continuously** (write tests alongside code)
5. **Evaluate regularly** (run evaluation after each major change)
6. **Iterate and improve** (use evaluation results to guide improvements)

---

## ğŸ¤ Contributing

This is a course/research project. To contribute:

1. Create a feature branch
2. Implement the module (follow skeleton structure)
3. Add unit tests
4. Update documentation
5. Submit pull request

---

## ğŸ“§ Support

For questions or issues:
- Check documentation in `/docs`
- Review workflow descriptions in `/n8n/workflows`
- Consult module README files
- Open an issue on GitHub

---

**Last Updated**: 2024-03-15  
**Version**: 1.0.0-skeleton
