# Intelligent Clinical Interview Analysis, Summarization & Retrieval System
## with Speaker Separation (Hybrid Architecture - Option C)

An academic information retrieval system that processes clinical interviews through both offline and live ingestion paths, converging into a unified retrieval, ranking, and evaluation pipeline.

---

## ğŸ—ï¸ Architectural Overview

### Core Principle: Two Ingestion Paths, One Unified Retrieval Core

**Offline Path:**
- Audio file upload â†’ Pyannote diarization â†’ Whisper transcription â†’ Speaker alignment â†’ Unified storage

**Live Path:**
- LiveKit real-time â†’ Speaker-separated streams â†’ Per-speaker Whisper â†’ Unified storage

**Unified Backend:**
- Shared data schemas
- Single indexing logic
- Common retrieval/ranking algorithms
- Unified evaluation pipeline

---

## ğŸ“‚ Repository Structure

```
/n8n/                       # Orchestration workflow definitions (logical flows, not full implementations)
  â”œâ”€â”€ workflows/
  â”‚   â”œâ”€â”€ offline_ingestion.md
  â”‚   â”œâ”€â”€ live_ingestion.md
  â”‚   â”œâ”€â”€ unified_retrieval.md
  â”‚   â””â”€â”€ evaluation.md
  â””â”€â”€ README.md

/backend/                   # Core Python-based ML/IR logic
  â”œâ”€â”€ api/                  # REST API endpoints for n8n integration
  â”œâ”€â”€ models/               # Data models and schema definitions
  â”œâ”€â”€ utils/                # Shared utilities
  â””â”€â”€ README.md

/diarization/               # Speaker separation logic for offline audio
  â”œâ”€â”€ pyannote_runner.py    # Pyannote.audio wrapper
  â”œâ”€â”€ config.py             # Diarization configuration
  â””â”€â”€ README.md

/transcription/             # Speech-to-text processing
  â”œâ”€â”€ whisper_client.py     # Whisper API/local wrapper
  â”œâ”€â”€ batch_transcribe.py   # Offline batch processing
  â”œâ”€â”€ stream_transcribe.py  # Live stream processing
  â””â”€â”€ README.md

/alignment/                 # Speaker-text alignment for offline path
  â”œâ”€â”€ speaker_aligner.py    # Maps diarization output to transcripts
  â”œâ”€â”€ segment_builder.py    # Creates speaker-labeled segments
  â””â”€â”€ README.md

/indexing/                  # Unified indexing for both ingestion paths
  â”œâ”€â”€ index_writer.py       # Write segments to vector/keyword index
  â”œâ”€â”€ embedder.py           # Sentence/semantic embeddings
  â”œâ”€â”€ schema_validator.py   # Ensures data consistency
  â””â”€â”€ README.md

/retrieval/                 # Query processing and ranking
  â”œâ”€â”€ retriever.py          # Speaker-aware retrieval logic
  â”œâ”€â”€ ranker.py             # Re-ranking algorithms
  â”œâ”€â”€ llm_explainer.py      # LLM-based answer generation
  â””â”€â”€ README.md

/evaluation/                # Metrics and benchmarking
  â”œâ”€â”€ metrics.py            # Precision@K, Recall@K, NDCG
  â”œâ”€â”€ evaluator.py          # Evaluation orchestrator
  â”œâ”€â”€ speaker_eval.py       # Patient-only/clinician-only evaluation
  â””â”€â”€ README.md

/frontend/                  # (Optional) Simple query interface
  â”œâ”€â”€ static/
  â”œâ”€â”€ templates/
  â””â”€â”€ README.md

/docs/                      # Documentation and design docs
  â”œâ”€â”€ architecture.md
  â”œâ”€â”€ data_schemas.md
  â”œâ”€â”€ setup_guide.md
  â””â”€â”€ evaluation_protocol.md

/tests/                     # Unit and integration tests
  â”œâ”€â”€ test_diarization/
  â”œâ”€â”€ test_retrieval/
  â””â”€â”€ test_evaluation/

/data/                      # Sample data and test fixtures (gitignored)
  â”œâ”€â”€ sample_audio/
  â”œâ”€â”€ ground_truth/
  â””â”€â”€ README.md

/config/                    # Configuration files
  â”œâ”€â”€ diarization_config.yaml
  â”œâ”€â”€ retrieval_config.yaml
  â””â”€â”€ evaluation_config.yaml

requirements.txt            # Python dependencies
docker-compose.yml          # Local development environment
.env.example                # Environment variables template
.gitignore
LICENSE
```

---

## ğŸ¯ Folder Responsibilities

### `/n8n`
Orchestration layer. Contains logical workflow descriptions (NOT full JSON exports) showing how components are triggered and connected.

### `/backend`
Core API layer that n8n calls. Exposes endpoints for triggering diarization, transcription, indexing, and retrieval.

### `/diarization`
Offline-only. Runs Pyannote.audio to identify "who spoke when" from audio files.

### `/transcription`
Dual-mode. Batch processing for offline, streaming for live. Both use Whisper.

### `/alignment`
Offline-only. Merges diarization timestamps with transcription text to create speaker-labeled segments.

### `/indexing`
Unified. Receives speaker-labeled segments from BOTH paths and writes to shared index (vector DB + metadata).

### `/retrieval`
Unified. Handles queries, retrieves relevant segments, ranks them, and optionally generates LLM explanations.

### `/evaluation`
Unified. Computes IR metrics and speaker-specific performance on test sets.

### `/frontend`
Optional web UI for demonstrations and manual testing.

### `/docs`
Design documents, setup guides, and architectural decisions.

---

## ğŸ”„ System Integration Flow

### Offline Ingestion
```
User uploads audio
    â†“
n8n triggers /api/diarization/run
    â†“
Pyannote identifies speaker segments
    â†“
n8n triggers /api/transcription/batch
    â†“
Whisper transcribes entire audio
    â†“
n8n triggers /api/alignment/align
    â†“
Speaker segments + transcript â†’ labeled segments
    â†“
n8n triggers /api/indexing/write
    â†“
Segments stored in unified index
```

### Live Ingestion
```
LiveKit session starts
    â†“
Webhook â†’ n8n triggers /api/transcription/stream
    â†“
Per-speaker audio â†’ Whisper (already separated)
    â†“
Direct speaker-labeled segments
    â†“
n8n triggers /api/indexing/write
    â†“
Segments stored in unified index
```

### Retrieval (Same for Both)
```
User query
    â†“
n8n triggers /api/retrieval/query
    â†“
Retrieve K candidates (speaker-aware filters optional)
    â†“
Rank by relevance
    â†“
LLM generates explanation grounded in segments
    â†“
Return results
```

---

## ğŸ“‹ Next Steps

1. Review `/docs/architecture.md` for detailed design
2. Check `/docs/data_schemas.md` for data structures
3. Follow `/docs/setup_guide.md` for environment setup
4. Implement skeletons incrementally per module
5. Run evaluation pipeline on sample data

---

## âš ï¸ Important Constraints

- **FREE tier only**: Whisper local/API free tier, Pyannote community model, open-source vector DB
- **No medical advice**: System is for IR research and education only
- **n8n for orchestration only**: ML logic lives in Python
- **Reproducible**: Fixed configs, seeded evaluation, documented protocols

---

## ğŸ“Š Why This Architecture?

**Modularity**: Each component has one clear responsibility  
**Unification**: Offline and live paths share 80% of code  
**Evaluation-friendly**: Single evaluation pipeline tests both modes  
**Course-ready**: Clear separation allows incremental teaching  
**Speaker-aware**: First-class support for patient/clinician distinction  

---

## ğŸ“ License

MIT License - For academic and educational use
